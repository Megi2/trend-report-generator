"""
ë°ì´í„° ì „ì²˜ë¦¬, ì¸ì½”ë”©, í´ëŸ¬ìŠ¤í„°ë§, ëŒ€í‘œ í”„ë ˆì´ì¦ˆ ì¶”ì¶œ, JSON ë‚´ë³´ë‚´ê¸°
"""
import pandas as pd
import json
from pathlib import Path
from typing import List, Dict, Any
import numpy as np

# í´ëŸ¬ìŠ¤í„°ë§ ê´€ë ¨ (í•„ìš”ì‹œ import)
# from sentence_transformers import SentenceTransformer
# import umap
# import hdbscan


def load_data(csv_path: str) -> pd.DataFrame:
    """
    CSV ë°ì´í„° ë¡œë“œ
    
    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        
    Returns:
        DataFrame
    """
    df = pd.read_csv(csv_path)
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
    return df


def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    ë°ì´í„° ì „ì²˜ë¦¬
    
    Args:
        df: ì›ë³¸ DataFrame
        
    Returns:
        ì „ì²˜ë¦¬ëœ DataFrame
    """
    # í•„ìš”í•œ ì „ì²˜ë¦¬ ìˆ˜í–‰
    # ì˜ˆ: ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ë°ì´í„° íƒ€ì… ë³€í™˜ ë“±
    print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
    return df


def encode_keywords(keywords: List[str], model_name: str = 'BAAI/bge-m3') -> np.ndarray:
    """
    í‚¤ì›Œë“œë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©
    
    Args:
        keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        model_name: ì‚¬ìš©í•  ëª¨ë¸ëª…
        
    Returns:
        ì¸ì½”ë”©ëœ ë²¡í„° ë°°ì—´
    """
    # TODO: SentenceTransformerë¥¼ ì‚¬ìš©í•œ ì¸ì½”ë”© êµ¬í˜„
    # model = SentenceTransformer(model_name)
    # embeddings = model.encode(keywords)
    # return embeddings
    print(f"âœ… í‚¤ì›Œë“œ ì¸ì½”ë”© ì™„ë£Œ: {len(keywords)}ê°œ")
    return np.array([])  # ì„ì‹œ


def cluster_keywords(embeddings: np.ndarray, min_cluster_size: int = 5) -> np.ndarray:
    """
    í‚¤ì›Œë“œë¥¼ í´ëŸ¬ìŠ¤í„°ë§
    
    Args:
        embeddings: ì¸ì½”ë”©ëœ ë²¡í„° ë°°ì—´
        min_cluster_size: ìµœì†Œ í´ëŸ¬ìŠ¤í„° í¬ê¸°
        
    Returns:
        í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ë°°ì—´
    """
    # TODO: UMAP + HDBSCANì„ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„°ë§ êµ¬í˜„
    # reducer = umap.UMAP(n_components=10, random_state=42)
    # reduced = reducer.fit_transform(embeddings)
    # clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)
    # labels = clusterer.fit_predict(reduced)
    # return labels
    print("âœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ")
    return np.array([])  # ì„ì‹œ


def extract_representative_phrases(
    df: pd.DataFrame,
    cluster_labels: np.ndarray,
    keywords: List[str]
) -> List[Dict[str, Any]]:
    """
    ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ëŒ€í‘œ í”„ë ˆì´ì¦ˆ ì¶”ì¶œ
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        cluster_labels: í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”
        keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        í”„ë ˆì´ì¦ˆë³„ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    # TODO: í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ëŒ€í‘œ í”„ë ˆì´ì¦ˆ ì¶”ì¶œ ë¡œì§ êµ¬í˜„
    # ê° í´ëŸ¬ìŠ¤í„°ì˜ í‚¤ì›Œë“œë“¤ì„ ê·¸ë£¹í™”í•˜ê³ 
    # ë…¸ì¶œìˆ˜/í´ë¦­ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í‘œ í”„ë ˆì´ì¦ˆ ì„ ì •
    
    phrase_data = []
    print("âœ… ëŒ€í‘œ í”„ë ˆì´ì¦ˆ ì¶”ì¶œ ì™„ë£Œ")
    return phrase_data


def export_to_json(data: List[Dict[str, Any]], output_path: str) -> None:
    """
    ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
    
    Args:
        data: ë‚´ë³´ë‚¼ ë°ì´í„°
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… JSON ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_path}")


def process_data(
    csv_path: str,
    output_json_path: str,
    month: str = None
) -> List[Dict[str, Any]]:
    """
    ì „ì²´ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    Args:
        csv_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        output_json_path: ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ
        month: ì›” ì •ë³´ (ì„ íƒì‚¬í•­)
        
    Returns:
        ì²˜ë¦¬ëœ í”„ë ˆì´ì¦ˆ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ“‚ ë°ì´í„° íŒŒì¼: {csv_path}")
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_data(csv_path)
    
    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    df_processed = preprocess_data(df)
    
    # 3. í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì¸ì½”ë”©
    # keywords = df_processed['ì†Œì¬ëª…'].unique().tolist()
    # embeddings = encode_keywords(keywords)
    
    # 4. í´ëŸ¬ìŠ¤í„°ë§
    # cluster_labels = cluster_keywords(embeddings)
    
    # 5. ëŒ€í‘œ í”„ë ˆì´ì¦ˆ ì¶”ì¶œ
    # phrase_data = extract_representative_phrases(df_processed, cluster_labels, keywords)
    
    # ì„ì‹œ: ê¸°ì¡´ JSON íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
    if Path(output_json_path).exists():
        print(f"ğŸ“‚ ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ: {output_json_path}")
        with open(output_json_path, 'r', encoding='utf-8') as f:
            phrase_data = json.load(f)
    else:
        # ìƒˆë¡œ ìƒì„± (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        phrase_data = []
        print("âš ï¸ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
    
    # 6. JSON ë‚´ë³´ë‚´ê¸°
    if phrase_data:
        export_to_json(phrase_data, output_json_path)
    
    return phrase_data

